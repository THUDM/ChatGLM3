# ChatGLM3

<p align="center">
ğŸ¤— <a href="https://huggingface.co/THUDM/chatglm3-6b" target="_blank">HF Repo</a> â€¢ ğŸ¤– <a href="https://modelscope.cn/models/ZhipuAI/chatglm3-6b" target="_blank">ModelScope</a>  â€¢ ğŸ¦ <a href="https://twitter.com/thukeg" target="_blank">Twitter</a> â€¢ ğŸ“ƒ <a href="https://arxiv.org/abs/2103.10360" target="_blank">[GLM@ACL 22]</a> <a href="https://github.com/THUDM/GLM" target="_blank">[GitHub]</a> â€¢ ğŸ“ƒ <a href="https://arxiv.org/abs/2210.02414" target="_blank">[GLM-130B@ICLR 23]</a> <a href="https://github.com/THUDM/GLM-130B" target="_blank">[GitHub]</a> <br>
</p>
<p align="center">
    ğŸ‘‹ åŠ å…¥æˆ‘ä»¬çš„ <a href="https://join.slack.com/t/chatglm/shared_invite/zt-25ti5uohv-A_hs~am_D3Q8XPZMpj7wwQ" target="_blank">Slack</a> å’Œ <a href="resources/WECHAT.md" target="_blank">WeChat</a>
</p>
<p align="center">
ğŸ“åœ¨ <a href="https://www.chatglm.cn">chatglm.cn</a> ä½“éªŒæ›´å¤§è§„æ¨¡çš„ ChatGLM æ¨¡å‹ã€‚
</p>

[Read this in English.](./README_en.md)

## ä»‹ç»

ChatGLM3 æ˜¯æ™ºè°±AIå’Œæ¸…åå¤§å­¦ KEG å®éªŒå®¤è”åˆå‘å¸ƒçš„æ–°ä¸€ä»£å¯¹è¯é¢„è®­ç»ƒæ¨¡å‹ã€‚ChatGLM3-6B æ˜¯ ChatGLM3 ç³»åˆ—ä¸­çš„å¼€æºæ¨¡å‹ï¼Œåœ¨ä¿ç•™äº†å‰ä¸¤ä»£æ¨¡å‹å¯¹è¯æµç•…ã€éƒ¨ç½²é—¨æ§›ä½ç­‰ä¼—å¤šä¼˜ç§€ç‰¹æ€§çš„åŸºç¡€ä¸Šï¼ŒChatGLM3-6B å¼•å…¥äº†å¦‚ä¸‹ç‰¹æ€§ï¼š

1. **æ›´å¼ºå¤§çš„åŸºç¡€æ¨¡å‹ï¼š** ChatGLM3-6B çš„åŸºç¡€æ¨¡å‹ ChatGLM3-6B-Base é‡‡ç”¨äº†æ›´å¤šæ ·çš„è®­ç»ƒæ•°æ®ã€æ›´å……åˆ†çš„è®­ç»ƒæ­¥æ•°å’Œæ›´åˆç†çš„è®­ç»ƒç­–ç•¥ã€‚åœ¨è¯­ä¹‰ã€æ•°å­¦ã€æ¨ç†ã€ä»£ç ã€çŸ¥è¯†ç­‰ä¸åŒè§’åº¦çš„æ•°æ®é›†ä¸Šæµ‹è¯„æ˜¾ç¤ºï¼Œ**ChatGLM3-6B-Base å…·æœ‰åœ¨ 10B ä»¥ä¸‹çš„åŸºç¡€æ¨¡å‹ä¸­æœ€å¼ºçš„æ€§èƒ½**ã€‚
2. **æ›´å®Œæ•´çš„åŠŸèƒ½æ”¯æŒï¼š** ChatGLM3-6B é‡‡ç”¨äº†å…¨æ–°è®¾è®¡çš„ [Prompt æ ¼å¼](PROMPT.md)ï¼Œé™¤æ­£å¸¸çš„å¤šè½®å¯¹è¯å¤–ã€‚åŒæ—¶åŸç”Ÿæ”¯æŒ[å·¥å…·è°ƒç”¨](tool_using/README.md)ï¼ˆFunction Callï¼‰ã€ä»£ç æ‰§è¡Œï¼ˆCode Interpreterï¼‰å’Œ Agent ä»»åŠ¡ç­‰å¤æ‚åœºæ™¯ã€‚
3. **æ›´å…¨é¢çš„å¼€æºåºåˆ—ï¼š** é™¤äº†å¯¹è¯æ¨¡å‹ [ChatGLM3-6B](https://huggingface.co/THUDM/chatglm3-6b) å¤–ï¼Œè¿˜å¼€æºäº†åŸºç¡€æ¨¡å‹ [ChatGLM3-6B-Base](https://huggingface.co/THUDM/chatglm3-6b-base)ã€é•¿æ–‡æœ¬å¯¹è¯æ¨¡å‹ [ChatGLM3-6B-32K](https://huggingface.co/THUDM/chatglm3-6b-32k)ã€‚ä»¥ä¸Šæ‰€æœ‰æƒé‡å¯¹å­¦æœ¯ç ”ç©¶**å®Œå…¨å¼€æ”¾**ï¼Œåœ¨å¡«å†™[é—®å·](https://open.bigmodel.cn/mla/form)è¿›è¡Œç™»è®°å**äº¦å…è®¸å…è´¹å•†ä¸šä½¿ç”¨**ã€‚

-----

ChatGLM3 å¼€æºæ¨¡å‹æ—¨åœ¨ä¸å¼€æºç¤¾åŒºä¸€èµ·æ¨åŠ¨å¤§æ¨¡å‹æŠ€æœ¯å‘å±•ï¼Œæ³è¯·å¼€å‘è€…å’Œå¤§å®¶éµå®ˆ[å¼€æºåè®®](MODEL_LICENSE)ï¼Œå‹¿å°†å¼€æºæ¨¡å‹å’Œä»£ç åŠåŸºäºå¼€æºé¡¹ç›®äº§ç”Ÿçš„è¡ç”Ÿç‰©ç”¨äºä»»ä½•å¯èƒ½ç»™å›½å®¶å’Œç¤¾ä¼šå¸¦æ¥å±å®³çš„ç”¨é€”ä»¥åŠç”¨äºä»»ä½•æœªç»è¿‡å®‰å…¨è¯„ä¼°å’Œå¤‡æ¡ˆçš„æœåŠ¡ã€‚ç›®å‰ï¼Œæœ¬é¡¹ç›®å›¢é˜ŸæœªåŸºäº **ChatGLM3 å¼€æºæ¨¡å‹**å¼€å‘ä»»ä½•åº”ç”¨ï¼ŒåŒ…æ‹¬ç½‘é¡µç«¯ã€å®‰å“ã€è‹¹æœ iOS åŠ Windows App ç­‰åº”ç”¨ã€‚

å°½ç®¡æ¨¡å‹åœ¨è®­ç»ƒçš„å„ä¸ªé˜¶æ®µéƒ½å°½åŠ›ç¡®ä¿æ•°æ®çš„åˆè§„æ€§å’Œå‡†ç¡®æ€§ï¼Œä½†ç”±äº ChatGLM3-6B æ¨¡å‹è§„æ¨¡è¾ƒå°ï¼Œä¸”æ¨¡å‹å—æ¦‚ç‡éšæœºæ€§å› ç´ å½±å“ï¼Œæ— æ³•ä¿è¯è¾“å‡ºå†…å®¹çš„å‡†ç¡®ã€‚åŒæ—¶æ¨¡å‹çš„è¾“å‡ºå®¹æ˜“è¢«ç”¨æˆ·çš„è¾“å…¥è¯¯å¯¼ã€‚**æœ¬é¡¹ç›®ä¸æ‰¿æ‹…å¼€æºæ¨¡å‹å’Œä»£ç å¯¼è‡´çš„æ•°æ®å®‰å…¨ã€èˆ†æƒ…é£é™©æˆ–å‘ç”Ÿä»»ä½•æ¨¡å‹è¢«è¯¯å¯¼ã€æ»¥ç”¨ã€ä¼ æ’­ã€ä¸å½“åˆ©ç”¨è€Œäº§ç”Ÿçš„é£é™©å’Œè´£ä»»ã€‚**

## æ¨¡å‹åˆ—è¡¨

| Model | Seq Length |                                                              Download                                                               
| :---: |:---------------------------:|:-----------------------------------------------------------------------------------------------------------------------------------:
| ChatGLM3-6B | 8k |      [HuggingFace](https://huggingface.co/THUDM/chatglm3-6b) \| [ModelScope](https://modelscope.cn/models/ZhipuAI/chatglm3-6b)      
| ChatGLM3-6B-Base | 8k | [HuggingFace](https://huggingface.co/THUDM/chatglm3-6b-base) \| [ModelScope](https://modelscope.cn/models/ZhipuAI/chatglm3-6b-base) 
| ChatGLM3-6B-32K | 32k |                                   [HuggingFace](https://huggingface.co/THUDM/chatglm3-6b-32k) \| [ModelScope](https://modelscope.cn/models/ZhipuAI/chatglm3-6b-32k)                                    

## è¯„æµ‹ç»“æœ

### å…¸å‹ä»»åŠ¡

æˆ‘ä»¬é€‰å–äº† 8 ä¸ªä¸­è‹±æ–‡å…¸å‹æ•°æ®é›†ï¼Œåœ¨ ChatGLM3-6B (base) ç‰ˆæœ¬ä¸Šè¿›è¡Œäº†æ€§èƒ½æµ‹è¯•ã€‚

| Model            | GSM8K | MATH | BBH  | MMLU | C-Eval | CMMLU | MBPP | AGIEval |
|------------------|:-----:|:----:|:----:|:----:|:------:|:-----:|:----:|:-------:|
| ChatGLM2-6B-Base | 32.4  | 6.5  | 33.7 | 47.9 |  51.7  | 50.0  |  -   |    -    |
| Best Baseline    | 52.1  | 13.1 | 45.0 | 60.1 |  63.5  | 62.2  | 47.5 |  45.8   
| ChatGLM3-6B-Base | 72.3  | 25.7 | 66.1 | 61.4 |  69.0  | 67.5  | 52.4 |  53.7   |
> Best Baseline æŒ‡çš„æ˜¯æ¨¡å‹å‚æ•°åœ¨ 10B ä»¥ä¸‹ã€åœ¨å¯¹åº”æ•°æ®é›†ä¸Šè¡¨ç°æœ€å¥½çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œä¸åŒ…æ‹¬åªé’ˆå¯¹æŸä¸€é¡¹ä»»åŠ¡è®­ç»ƒè€Œæœªä¿æŒé€šç”¨èƒ½åŠ›çš„æ¨¡å‹ã€‚

> å¯¹ ChatGLM3-6B-Base çš„æµ‹è¯•ä¸­ï¼ŒBBH é‡‡ç”¨ 3-shot æµ‹è¯•ï¼Œéœ€è¦æ¨ç†çš„ GSM8Kã€MATH é‡‡ç”¨ 0-shot CoT æµ‹è¯•ï¼ŒMBPP é‡‡ç”¨ 0-shot ç”Ÿæˆåè¿è¡Œæµ‹ä¾‹è®¡ç®— Pass@1 ï¼Œå…¶ä»–é€‰æ‹©é¢˜ç±»å‹æ•°æ®é›†å‡é‡‡ç”¨ 0-shot æµ‹è¯•ã€‚

æˆ‘ä»¬åœ¨å¤šä¸ªé•¿æ–‡æœ¬åº”ç”¨åœºæ™¯ä¸‹å¯¹ ChatGLM3-6B-32K è¿›è¡Œäº†äººå·¥è¯„ä¼°æµ‹è¯•ã€‚ä¸äºŒä»£æ¨¡å‹ç›¸æ¯”ï¼Œå…¶æ•ˆæœå¹³å‡æå‡äº†è¶…è¿‡ 50%ã€‚åœ¨è®ºæ–‡é˜…è¯»ã€æ–‡æ¡£æ‘˜è¦å’Œè´¢æŠ¥åˆ†æç­‰åº”ç”¨ä¸­ï¼Œè¿™ç§æå‡å°¤ä¸ºæ˜¾è‘—ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜åœ¨ LongBench è¯„æµ‹é›†ä¸Šå¯¹æ¨¡å‹è¿›è¡Œäº†æµ‹è¯•ï¼Œå…·ä½“ç»“æœå¦‚ä¸‹è¡¨æ‰€ç¤º

| Model                |  å¹³å‡ |  Summary | Single-Doc QA |  Multi-Doc QA | Code | Few-shot | Synthetic | 
|----------------------|:-----:|:----:|:----:|:----:|:------:|:-----:|:-----:|
| ChatGLM2-6B-32K   |  41.5 | 24.8 | 37.6 | 34.7 |  52.8  |  51.3 | 47.7 | 
| ChatGLM3-6B-32K   |  50.2 | 26.6 | 45.8 | 46.1 |  56.2  |  61.2 | 65 |


## ä½¿ç”¨æ–¹å¼

### ç¯å¢ƒå®‰è£…
é¦–å…ˆéœ€è¦ä¸‹è½½æœ¬ä»“åº“ï¼š
```shell
git clone https://github.com/THUDM/ChatGLM3
cd ChatGLM3
```

ç„¶åä½¿ç”¨ pip å®‰è£…ä¾èµ–ï¼š
```
pip install -r requirements.txt
```
å…¶ä¸­ `transformers` åº“ç‰ˆæœ¬æ¨èä¸º `4.30.2`ï¼Œ`torch` æ¨èä½¿ç”¨ 2.0 åŠä»¥ä¸Šçš„ç‰ˆæœ¬ï¼Œä»¥è·å¾—æœ€ä½³çš„æ¨ç†æ€§èƒ½ã€‚

### ç»¼åˆ Demo

æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªé›†æˆä»¥ä¸‹ä¸‰ç§åŠŸèƒ½çš„ç»¼åˆ Demoï¼Œè¿è¡Œæ–¹æ³•è¯·å‚è€ƒ [ç»¼åˆ Demo](composite_demo/README.md)

- Chat: å¯¹è¯æ¨¡å¼ï¼Œåœ¨æ­¤æ¨¡å¼ä¸‹å¯ä»¥ä¸æ¨¡å‹è¿›è¡Œå¯¹è¯ã€‚
- Tool: å·¥å…·æ¨¡å¼ï¼Œæ¨¡å‹é™¤äº†å¯¹è¯å¤–ï¼Œè¿˜å¯ä»¥é€šè¿‡å·¥å…·è¿›è¡Œå…¶ä»–æ“ä½œã€‚
    ![tool](resources/tool.png)
- Code Interpreter: ä»£ç è§£é‡Šå™¨æ¨¡å¼ï¼Œæ¨¡å‹å¯ä»¥åœ¨ä¸€ä¸ª Jupyter ç¯å¢ƒä¸­æ‰§è¡Œä»£ç å¹¶è·å–ç»“æœï¼Œä»¥å®Œæˆå¤æ‚ä»»åŠ¡ã€‚
    ![code](resources/heart.png)

### ä»£ç è°ƒç”¨ 

å¯ä»¥é€šè¿‡å¦‚ä¸‹ä»£ç è°ƒç”¨ ChatGLM æ¨¡å‹æ¥ç”Ÿæˆå¯¹è¯ï¼š

```python
>>> from transformers import AutoTokenizer, AutoModel
>>> tokenizer = AutoTokenizer.from_pretrained("THUDM/chatglm3-6b", trust_remote_code=True)
>>> model = AutoModel.from_pretrained("THUDM/chatglm3-6b", trust_remote_code=True, device='cuda')
>>> model = model.eval()
>>> response, history = model.chat(tokenizer, "ä½ å¥½", history=[])
>>> print(response)
ä½ å¥½ğŸ‘‹!æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM3-6B,å¾ˆé«˜å…´è§åˆ°ä½ ,æ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚
>>> response, history = model.chat(tokenizer, "æ™šä¸Šç¡ä¸ç€åº”è¯¥æ€ä¹ˆåŠ", history=history)
>>> print(response)
æ™šä¸Šç¡ä¸ç€å¯èƒ½ä¼šè®©ä½ æ„Ÿåˆ°ç„¦è™‘æˆ–ä¸èˆ’æœ,ä½†ä»¥ä¸‹æ˜¯ä¸€äº›å¯ä»¥å¸®åŠ©ä½ å…¥ç¡çš„æ–¹æ³•:

1. åˆ¶å®šè§„å¾‹çš„ç¡çœ æ—¶é—´è¡¨:ä¿æŒè§„å¾‹çš„ç¡çœ æ—¶é—´è¡¨å¯ä»¥å¸®åŠ©ä½ å»ºç«‹å¥åº·çš„ç¡çœ ä¹ æƒ¯,ä½¿ä½ æ›´å®¹æ˜“å…¥ç¡ã€‚å°½é‡åœ¨æ¯å¤©çš„ç›¸åŒæ—¶é—´ä¸ŠåºŠ,å¹¶åœ¨åŒä¸€æ—¶é—´èµ·åºŠã€‚
2. åˆ›é€ ä¸€ä¸ªèˆ’é€‚çš„ç¡çœ ç¯å¢ƒ:ç¡®ä¿ç¡çœ ç¯å¢ƒèˆ’é€‚,å®‰é™,é»‘æš—ä¸”æ¸©åº¦é€‚å®œã€‚å¯ä»¥ä½¿ç”¨èˆ’é€‚çš„åºŠä¸Šç”¨å“,å¹¶ä¿æŒæˆ¿é—´é€šé£ã€‚
3. æ”¾æ¾èº«å¿ƒ:åœ¨ç¡å‰åšäº›æ”¾æ¾çš„æ´»åŠ¨,ä¾‹å¦‚æ³¡ä¸ªçƒ­æ°´æ¾¡,å¬äº›è½»æŸ”çš„éŸ³ä¹,é˜…è¯»ä¸€äº›æœ‰è¶£çš„ä¹¦ç±ç­‰,æœ‰åŠ©äºç¼“è§£ç´§å¼ å’Œç„¦è™‘,ä½¿ä½ æ›´å®¹æ˜“å…¥ç¡ã€‚
4. é¿å…é¥®ç”¨å«æœ‰å’–å•¡å› çš„é¥®æ–™:å’–å•¡å› æ˜¯ä¸€ç§åˆºæ¿€æ€§ç‰©è´¨,ä¼šå½±å“ä½ çš„ç¡çœ è´¨é‡ã€‚å°½é‡é¿å…åœ¨ç¡å‰é¥®ç”¨å«æœ‰å’–å•¡å› çš„é¥®æ–™,ä¾‹å¦‚å’–å•¡,èŒ¶å’Œå¯ä¹ã€‚
5. é¿å…åœ¨åºŠä¸Šåšä¸ç¡çœ æ— å…³çš„äº‹æƒ…:åœ¨åºŠä¸Šåšäº›ä¸ç¡çœ æ— å…³çš„äº‹æƒ…,ä¾‹å¦‚çœ‹ç”µå½±,ç©æ¸¸æˆæˆ–å·¥ä½œç­‰,å¯èƒ½ä¼šå¹²æ‰°ä½ çš„ç¡çœ ã€‚
6. å°è¯•å‘¼å¸æŠ€å·§:æ·±å‘¼å¸æ˜¯ä¸€ç§æ”¾æ¾æŠ€å·§,å¯ä»¥å¸®åŠ©ä½ ç¼“è§£ç´§å¼ å’Œç„¦è™‘,ä½¿ä½ æ›´å®¹æ˜“å…¥ç¡ã€‚è¯•ç€æ…¢æ…¢å¸æ°”,ä¿æŒå‡ ç§’é’Ÿ,ç„¶åç¼“æ…¢å‘¼æ°”ã€‚

å¦‚æœè¿™äº›æ–¹æ³•æ— æ³•å¸®åŠ©ä½ å…¥ç¡,ä½ å¯ä»¥è€ƒè™‘å’¨è¯¢åŒ»ç”Ÿæˆ–ç¡çœ ä¸“å®¶,å¯»æ±‚è¿›ä¸€æ­¥çš„å»ºè®®ã€‚
```

#### ä»æœ¬åœ°åŠ è½½æ¨¡å‹
ä»¥ä¸Šä»£ç ä¼šç”± `transformers` è‡ªåŠ¨ä¸‹è½½æ¨¡å‹å®ç°å’Œå‚æ•°ã€‚å®Œæ•´çš„æ¨¡å‹å®ç°åœ¨ [Hugging Face Hub](https://huggingface.co/THUDM/chatglm3-6b)ã€‚å¦‚æœä½ çš„ç½‘ç»œç¯å¢ƒè¾ƒå·®ï¼Œä¸‹è½½æ¨¡å‹å‚æ•°å¯èƒ½ä¼šèŠ±è´¹è¾ƒé•¿æ—¶é—´ç”šè‡³å¤±è´¥ã€‚æ­¤æ—¶å¯ä»¥å…ˆå°†æ¨¡å‹ä¸‹è½½åˆ°æœ¬åœ°ï¼Œç„¶åä»æœ¬åœ°åŠ è½½ã€‚

ä» Hugging Face Hub ä¸‹è½½æ¨¡å‹éœ€è¦å…ˆ[å®‰è£…Git LFS](https://docs.github.com/zh/repositories/working-with-files/managing-large-files/installing-git-large-file-storage)ï¼Œç„¶åè¿è¡Œ
```Shell
git clone https://huggingface.co/THUDM/chatglm3-6b
```

å¦‚æœä»ä½ ä» HuggingFace ä¸‹è½½æ¯”è¾ƒæ…¢ï¼Œä¹Ÿå¯ä»¥ä» [ModelScope](https://modelscope.cn/models/ZhipuAI/chatglm3-6b) 
ä¸­ä¸‹è½½ã€‚

### ç½‘é¡µç‰ˆå¯¹è¯ Demo
![web-demo](resources/web-demo.gif)
å¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤å¯åŠ¨åŸºäº Gradio çš„ç½‘é¡µç‰ˆ demoï¼š
```shell
python web_demo.py
```

![web-demo](resources/web-demo2.png)

å¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤å¯åŠ¨åŸºäº Streamlit çš„ç½‘é¡µç‰ˆ demoï¼š
```shell
streamlit run web_demo2.py
```

ç½‘é¡µç‰ˆ demo ä¼šè¿è¡Œä¸€ä¸ª Web Serverï¼Œå¹¶è¾“å‡ºåœ°å€ã€‚åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€è¾“å‡ºçš„åœ°å€å³å¯ä½¿ç”¨ã€‚ ç»æµ‹è¯•ï¼ŒåŸºäº Streamlit çš„ç½‘é¡µç‰ˆ Demo ä¼šæ›´æµç•…ã€‚

### å‘½ä»¤è¡Œå¯¹è¯ Demo

![cli-demo](resources/cli-demo.png)

è¿è¡Œä»“åº“ä¸­ [cli_demo.py](cli_demo.py)ï¼š

```shell
python cli_demo.py
```

ç¨‹åºä¼šåœ¨å‘½ä»¤è¡Œä¸­è¿›è¡Œäº¤äº’å¼çš„å¯¹è¯ï¼Œåœ¨å‘½ä»¤è¡Œä¸­è¾“å…¥æŒ‡ç¤ºå¹¶å›è½¦å³å¯ç”Ÿæˆå›å¤ï¼Œè¾“å…¥ `clear` å¯ä»¥æ¸…ç©ºå¯¹è¯å†å²ï¼Œè¾“å…¥ `stop` ç»ˆæ­¢ç¨‹åºã€‚

### API éƒ¨ç½²
æ„Ÿè°¢ [@xusenlinzy](https://github.com/xusenlinzy) å®ç°äº† OpenAI æ ¼å¼çš„æµå¼ API éƒ¨ç½²ï¼Œå¯ä»¥ä½œä¸ºä»»æ„åŸºäº ChatGPT çš„åº”ç”¨çš„åç«¯ï¼Œæ¯”å¦‚ [ChatGPT-Next-Web](https://github.com/Yidadaa/ChatGPT-Next-Web)ã€‚å¯ä»¥é€šè¿‡è¿è¡Œä»“åº“ä¸­çš„[openai_api.py](openai_api.py) è¿›è¡Œéƒ¨ç½²ï¼š
```shell
python openai_api.py
```
è¿›è¡Œ API è°ƒç”¨çš„ç¤ºä¾‹ä»£ç ä¸º
```python
import openai
if __name__ == "__main__":
    openai.api_base = "http://localhost:8000/v1"
    openai.api_key = "none"
    for chunk in openai.ChatCompletion.create(
        model="chatglm3-6b",
        messages=[
            {"role": "user", "content": "ä½ å¥½"}
        ],
        stream=True
    ):
        if hasattr(chunk.choices[0].delta, "content"):
            print(chunk.choices[0].delta.content, end="", flush=True)
```

### å·¥å…·è°ƒç”¨
å…³äºå·¥å…·è°ƒç”¨çš„æ–¹æ³•è¯·å‚è€ƒ [å·¥å…·è°ƒç”¨](tool_using/README.md)ã€‚

## ä½æˆæœ¬éƒ¨ç½²

è¯·è§ [DEPLOYMENT.md](DEPLOYMENT.md)ã€‚

## å¼•ç”¨

å¦‚æœä½ è§‰å¾—æˆ‘ä»¬çš„å·¥ä½œæœ‰å¸®åŠ©çš„è¯ï¼Œè¯·è€ƒè™‘å¼•ç”¨ä¸‹åˆ—è®ºæ–‡ã€‚

```
@article{zeng2022glm,
  title={Glm-130b: An open bilingual pre-trained model},
  author={Zeng, Aohan and Liu, Xiao and Du, Zhengxiao and Wang, Zihan and Lai, Hanyu and Ding, Ming and Yang, Zhuoyi and Xu, Yifan and Zheng, Wendi and Xia, Xiao and others},
  journal={arXiv preprint arXiv:2210.02414},
  year={2022}
}
```
```
@inproceedings{du2022glm,
  title={GLM: General Language Model Pretraining with Autoregressive Blank Infilling},
  author={Du, Zhengxiao and Qian, Yujie and Liu, Xiao and Ding, Ming and Qiu, Jiezhong and Yang, Zhilin and Tang, Jie},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={320--335},
  year={2022}
}
```
